{
  "hash": "d46ef8343d85059c1a2921d9027638c1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands on Exercise 11\"\nauthor: \"Xu Haiyang\"\ndate: \"7 November, 2024\" \ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  freeze: true\n---\n\n\n\n## **Overview**\n\nPredictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\n\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n## **The Data**\n\n-   **Aspatial dataset**:\n\n    -   HDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.\n\n-   **Geospatial dataset**:\n\n    -   *MP14_SUBZONE_WEB_PL*: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg\n\n-   **Locational factors with geographic coordinates**:\n\n    -   Downloaded from **Data.gov.sg**.\n\n        -   **Eldercare** data is a list of eldercare in Singapore. It is in shapefile format.\n\n        -   **Hawker Centre** data is a list of hawker centres in Singapore. It is in geojson format.\n\n        -   **Parks** data is a list of parks in Singapore. It is in geojson format.\n\n        -   **Supermarket** data is a list of supermarkets in Singapore. It is in geojson format.\n\n        -   **CHAS clinics** data is a list of CHAS clinics in Singapore. It is in geojson format.\n\n        -   **Childcare service** data is a list of childcare services in Singapore. It is in geojson format.\n\n        -   **Kindergartens** data is a list of kindergartens in Singapore. It is in geojson format.\n\n    -   Downloaded from **Datamall.lta.gov.sg**.\n\n        -   **MRT** data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.\n\n        -   **Bus stops** data is a list of bus stops in Singapore. It is in shapefile format.\n\n-   **Locational factors without geographic coordinates**:\n\n    -   Downloaded from **Data.gov.sg**.\n\n        -   **Primary school** data is extracted from the list on General information of schools from data.gov portal. It is in csv format.\n\n    -   Retrieved/Scraped from **other sources**\n\n        -   **CBD** coordinates obtained from Google.\n\n        -   **Shopping malls** data is a list of Shopping malls in Singapore obtained from [Wikipedia](https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore).\n\n        -   **Good primary schools** is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at [Local Salary Forum](https://www.salary.sg/2021/best-primary-schools-2021-by-popularity).\n\n## **Installing and Loading R packages**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse)\n```\n:::\n\n\n\n## **Preparing Data**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdata <- read_rds(\"data/model/mdata.rds\")\n```\n:::\n\n\n\nHere, I load the primary dataset (`mdata`), which contains spatial data on property resale prices and various features.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nresale_split <- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data <- training(resale_split)\ntest_data <- testing(resale_split)\n```\n:::\n\n\n\nThe data is split into training (65%) and testing (35%) sets to allow for model training and performance evaluation on unseen data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")\n```\n:::\n\n\n\n## **Computing Correlation Matrix**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmdata_nogeo <- mdata %>%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex11_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nThe geometry column is dropped to calculate correlations on non-spatial features.\n\nThis generates a correlation matrix plot for the selected numerical features, helping identify multicollinearity or strong relationships between predictors.\n\n## **Retriving the Stored Data**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- read_rds(\"data/model/train_data.rds\")\ntest_data <- read_rds(\"data/model/test_data.rds\")\n```\n:::\n\n\n\n## **Building a non-spatial multiple linear regression**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice_mlr <- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nsummary(price_mlr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              107601.073  10601.261  10.150  < 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  < 2e-16 ***\nstorey_order              14299.298    339.115  42.167  < 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  < 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  < 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  < 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  < 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  < 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  < 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  < 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,\tAdjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\nThis code fits a multiple linear regression (MLR) model predicting resale prices based on property and locational attributes. The summary output provides insights into model performance, coefficients, and significance levels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(price_mlr, \"data/model/price_mlr.rds\" ) \n```\n:::\n\n\n\n## **Preparing coordinates data**\n\n### **Extracting coordinates data**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords <- st_coordinates(mdata)\ncoords_train <- st_coordinates(train_data)\ncoords_test <- st_coordinates(test_data)\n```\n:::\n\n\n\nExtracts coordinate information from the spatial data, which is required for geographical random forest modeling.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoords_train <- write_rds(coords_train, \"data/model/coords_train.rds\" )\ncoords_test <- write_rds(coords_test, \"data/model/coords_test.rds\" )\n```\n:::\n\n\n\nThe coordinate data for both training and testing sets are saved for later use.\n\n### **Droping geometry field**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_data <- train_data %>% \n  st_drop_geometry()\n```\n:::\n\n\n\nDropping geometry from the training data allows non-spatial machine learning models (like random forest) to be applied without spatial data constraints.\n\n## **Calibrating Random Forest Model**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nrf <- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data)\nrf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728 \n```\n\n\n:::\n:::\n\n\n\nThis code trains a traditional (non-spatial) random forest model on the training data. The `ranger` package is used for efficient random forest modeling.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(rf, \"data/model/rf.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrf <- read_rds(\"data/model/rf.rds\")\nrf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728 \n```\n\n\n:::\n:::\n\n\n\n## **Calibrating Geographical Random Forest Model**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\ngwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nNumber of Observations: 10335\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNumber of Independent Variables: 14\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nKernel: Adaptive\nNeightbours: 55\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n--------------- Global ML Model Summary ---------------\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       700081018 \nR squared (OOB):                  0.9515468 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nImportance:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.376510e+12             1.413229e+13             2.991844e+13 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            5.312697e+13             7.017513e+12             5.506719e+12 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.446857e+12             4.825986e+12             4.173165e+12 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            2.879598e+12             1.028775e+12             1.701318e+12 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            1.564038e+12             7.214027e+12 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nMean Square Error (Not OOB): 173279991.32\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nR-squared (Not OOB) %: 98.801\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAIC (Not OOB): 196089.283\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAICc (Not OOB): 196089.33\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n--------------- Local Model Summary ---------------\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nResiduals OOB:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-236112.0  -13033.7     444.4     593.8   14831.5  358041.7 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nResiduals Predicted (Not OOB):\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-79279.83  -3510.70     54.56     50.98   3909.85  83074.08 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nLocal Variable Importance:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                               Min          Max        Mean         StD\nfloor_area_sqm                   0 401562922035 18210850992 41426270899\nstorey_order             302736445 243728744368 16368419468 23620589843\nremaining_lease_mths     696564138 546463600727 34119912443 70328183398\nPROX_CBD                  55173040 382484896335 12154563393 29293290548\nPROX_ELDERLYCARE          45182031 344081962746 10597657883 24546405941\nPROX_HAWKER               43516026 342597797419 10551807020 23408387903\nPROX_MRT                  54234551 299075025906  9873129985 21055852211\nPROX_PARK                 49919822 322633843469  9353956995 19517077658\nPROX_MALL                 43296133 433263607933 11247374493 27537334970\nPROX_SUPERMARKET          52665827 417310417234 10802122271 26572460731\nWITHIN_350M_KINDERGARTEN         0 186468064682  2848177740 12928886968\nWITHIN_350M_CHILDCARE            0 255236737234  5526292324 18109971102\nWITHIN_350M_BUS                  0 193828795378  4747552546 11886064288\nWITHIN_1KM_PRISCH                0 178360608427  1778262602  7163381668\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nMean squared error (OOB): 930426169.333\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nR-squared (OOB) %: 93.56\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAIC (OOB): 213459.669\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAICc (OOB): 213459.716\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nMean squared error Predicted (Not OOB): 73859413.696\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nR-squared Predicted (Not OOB) %: 99.489\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAIC Predicted (Not OOB): 187276.161\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAICc Predicted (Not OOB): 187276.208\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nCalculation time (in seconds): 4.1543\n```\n\n\n:::\n:::\n\n\n\nThe geographical random forest model (`grf`) is trained using an adaptive bandwidth of 55, meaning the model's influence radius varies based on location density. This helps capture spatial heterogeneity across the study area.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_adaptive <- read_rds(\"data/model/gwRF_adaptive.rds\")\n```\n:::\n\n\n\n### **Predicting by using test data**\n\n#### Preparing the test data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n```\n:::\n\n\n\nThe coordinates are added to the test data for prediction, and the geometry is dropped to avoid conflicts during prediction.\n\n#### Predicting with test data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngwRF_pred <- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n```\n:::\n\n\n\nPredictions are generated using the GRF model on the test data, considering local influence.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- write_rds(gwRF_pred, \"data/model/GRF_pred.rds\")\n```\n:::\n\n\n\n#### Converting the predicting output into a data frame\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGRF_pred <- read_rds(\"data/model/GRF_pred.rds\")\nGRF_pred_df <- as.data.frame(GRF_pred)\n```\n:::\n\n\n\nThe prediction results are loaded and converted to a data frame for easier manipulation and evaluation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data_p <- cbind(test_data, GRF_pred_df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(test_data_p, \"data/model/test_data_p.rds\")\n```\n:::\n\n\n\nThe predictions are merged with the original test data, and the combined data frame is saved.\n\n### **Calculating Root Mean Square Error**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 27302.9\n```\n\n\n:::\n:::\n\n\n\nThe RMSE is calculated to assess the prediction accuracy of the GRF model by comparing predicted and actual resale prices in the test data.\n\n### **Visualising the predicted values**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex11_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\nThis scatter plot visualizes the relationship between predicted and actual resale prices, providing a quick visual assessment of the modelâ€™s accuracy. Ideally, points should align along the 1:1 line if predictions are close to actual values.\n",
    "supporting": [
      "Hands-on_Ex11_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}